{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unj_RY_k377f",
        "outputId": "ccd278ed-5fca-4a52-9c6f-b25a63689cee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting umap\n",
            "  Using cached umap-0.1.1.tar.gz (3.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (0.5.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (1.13.1)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.61.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from umap-learn) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn) (0.44.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Building wheels for collected packages: umap\n",
            "  Building wheel for umap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap: filename=umap-0.1.1-py3-none-any.whl size=3542 sha256=d789940c47192ac27af4c1e854614759cc11fb013ee37f404143721228772af6\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/d8/73/e9eb3334baaad795ff0278363ff1aca7568bdf2793e452a527\n",
            "Successfully built umap\n",
            "Installing collected packages: umap\n",
            "Successfully installed umap-0.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.24.4 umap==0.1.1 umap-learn==0.5.7 pandas==2.2.2 scikit-learn==1.5.2 matplotlib==3.10.0 scipy==1.13.1 gensim==4.3.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpCMqTiB4RO_"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "from scipy.stats import entropy\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeiNYyUa5cVP"
      },
      "source": [
        "Load preprocessed files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aH1nQOZ5VpQ"
      },
      "outputs": [],
      "source": [
        "with open('filtered_docs_biology.pkl', 'rb') as f:\n",
        "    filtered_docs_biology = pickle.load(f)\n",
        "\n",
        "with open('umap_result_biology.pkl', 'rb') as f:\n",
        "    umap_result_biology = pickle.load(f)\n",
        "\n",
        "with open('preprocessed_docs.pkl', 'rb') as f:\n",
        "    preprocessed_docs = pickle.load(f)\n",
        "\n",
        "with open('lda_model.pkl', 'rb') as f:\n",
        "    lda_model = pickle.load(f)\n",
        "\n",
        "with open('bow_corpus.pkl', 'rb') as f:\n",
        "    bow_corpus = pickle.load(f)\n",
        "\n",
        "with open('dictionary.dict', 'rb') as f:\n",
        "    dictionary = pickle.load(f)\n",
        "\n",
        "# Load the CSV file containing all documents with Year, Abstract, and Processed columns\n",
        "file_name = 'preprocessed_docs.csv'\n",
        "df = pd.read_csv(file_name, low_memory=False)\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Load the BoA Leiden labels\n",
        "file_name = 'leiden_labels_biology.csv'\n",
        "leiden_labels_biology = pd.read_csv(file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD_Nose16vsU"
      },
      "source": [
        "Generate a CSV file containing only the filtered BoA documents with Year, Abstract and Processed columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDrKuzKI5TPk"
      },
      "outputs": [],
      "source": [
        "# Get the indices of the filtered docs and create a new dataframe\n",
        "filtered_indices = [i for i, doc in enumerate(preprocessed_docs) if doc in filtered_docs_biology]\n",
        "filtered_df_with_year = df.loc[filtered_indices]\n",
        "\n",
        "file_name = 'preprocessed_docs_biology.csv'\n",
        "filtered_df_with_year.to_csv(file_name, index=False)\n",
        "\n",
        "df = filtered_df_with_year"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSEx1WRC72eq"
      },
      "source": [
        "Plot UMAP divided by decades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYcrS9gR8L0Y"
      },
      "outputs": [],
      "source": [
        "# Create a new column for year ranges\n",
        "def classify_year_range(year):\n",
        "    if 1975 <= year <= 1984:\n",
        "        return '1975-1984'\n",
        "    elif 1985 <= year <= 1994:\n",
        "        return '1985-1994'\n",
        "    elif 1995 <= year <= 2004:\n",
        "        return '1995-2004'\n",
        "    elif 2005 <= year <= 2014:\n",
        "        return '2005-2014'\n",
        "    elif 2015 <= year <= 2023:\n",
        "        return '2015-2023'\n",
        "    else:\n",
        "        return 'Unknown'\n",
        "\n",
        "df['Year_Range'] = filtered_df_with_year['Year'].apply(classify_year_range)\n",
        "\n",
        "# Create a dataframe with umap embeddings and year range\n",
        "umap_df = pd.DataFrame(umap_result_biology, columns=['UMAP1', 'UMAP2'])\n",
        "combined_df = pd.concat([umap_df, df[['Year_Range']]], axis=1)\n",
        "year_ranges = ['1975-1984', '1985-1994', '1995-2004', '2005-2014', '2015-2023']\n",
        "\n",
        "# Plot individual UMAPs for each year range\n",
        "plt.figure(figsize=(25, 5))\n",
        "for i, year_range in enumerate(year_ranges):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    subset = combined_df[combined_df['Year_Range'] == year_range]\n",
        "    plt.scatter(subset['UMAP1'], subset['UMAP2'], c='navy', s=0.5, alpha=0.2)\n",
        "    plt.title(f'UMAP Biology of Aging ({year_range})')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.gca().spines['top'].set_visible(False)\n",
        "    plt.gca().spines['right'].set_visible(False)\n",
        "    plt.gca().spines['left'].set_visible(False)\n",
        "    plt.gca().spines['bottom'].set_visible(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('Year ranges UMAP BoA.png', dpi=600)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXm4DtWM9M-T"
      },
      "source": [
        "Temporal evolution of cluster proportions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eGNjK_09XGc"
      },
      "outputs": [],
      "source": [
        "# Define cluster names\n",
        "cluster_names = {\n",
        "    0: 'GWAS',\n",
        "    1: 'Gene regulation',\n",
        "    2: 'Cancer',\n",
        "    3: 'Epigenetics',\n",
        "    4: 'Insulin/IGF pathway',\n",
        "    5: 'Oxidative stress',\n",
        "    6: 'Stem cells',\n",
        "    7: 'Mesenchymal stem cells',\n",
        "    8: 'Mouse models',\n",
        "    9: 'Biochemistry',\n",
        "    10: 'Neuroscience',\n",
        "    11: 'Comparative studies',\n",
        "    12: 'Skin',\n",
        "    13: 'Immunology',\n",
        "    14: 'Clinical genetics',\n",
        "    15: 'Mitochondria',\n",
        "    16: 'Protein biology',\n",
        "    17: 'Senescence',\n",
        "    18: 'Genomic stability',\n",
        "    19: \"Alzheimer's\",\n",
        "    20: 'Muscle',\n",
        "    21: 'RNA biology',\n",
        "    22: 'Receptor biology',\n",
        "    23: 'Cytokines',\n",
        "    24: 'Telomeres',\n",
        "    25: 'Sirtuins & mTOR',\n",
        "    26: 'Autophagy'\n",
        "}\n",
        "\n",
        "# Add Leiden labels to the dataframe\n",
        "df['Cluster'] = leiden_labels_biology['leiden']\n",
        "\n",
        "# Group by year and cluster to get the count of documents per cluster per year\n",
        "yearly_counts = df.groupby(['Year', 'Cluster']).size().unstack(fill_value=0)\n",
        "total_docs_per_year = yearly_counts.sum(axis=1)\n",
        "proportion_counts = yearly_counts.div(total_docs_per_year, axis=0)\n",
        "moving_avg = proportion_counts.rolling(window=5, min_periods=1).mean()\n",
        "\n",
        "# Filter data for the years 1975 to 2023\n",
        "moving_avg_filtered = moving_avg[(moving_avg.index >= 1975) & (moving_avg.index <= 2023)]\n",
        "\n",
        "# Calculate total documents per cluster\n",
        "total_per_cluster = yearly_counts.sum().sort_values(ascending=False)\n",
        "\n",
        "# Re-order cluster_names based on total document count\n",
        "sorted_cluster_names = {cluster: cluster_names[cluster] for cluster in total_per_cluster.index if cluster in cluster_names}\n",
        "\n",
        "# Plot the results in a single PDF\n",
        "fig, axes = plt.subplots(nrows=6, ncols=6, figsize=(40, 25))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (cluster, name) in enumerate(sorted_cluster_names.items()):\n",
        "    if cluster in moving_avg_filtered.columns:\n",
        "        axes[idx].plot(moving_avg_filtered.index, moving_avg_filtered[cluster], linestyle='-', color='navy')\n",
        "        axes[idx].set_title(f'{name}', fontsize=24)\n",
        "        axes[idx].set_xlabel('Year', fontsize=24)\n",
        "        axes[idx].set_ylabel('Proportion of Documents', fontsize=20)\n",
        "        axes[idx].tick_params(axis='both', which='major', labelsize=20)\n",
        "        axes[idx].grid(False)\n",
        "    else:\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "# Hide any unused subplots\n",
        "for ax in axes[len(sorted_cluster_names):]:\n",
        "    ax.set_visible(False)\n",
        "plt.tight_layout()\n",
        "plt.savefig('Cluster_Evolution_Panel_BoA.pdf')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD6TJPTw-nqx"
      },
      "source": [
        "Calculate mean publication year per cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBQZSZdp-p4n"
      },
      "outputs": [],
      "source": [
        "# Filter documents from 1975 or newer and add leiden labels\n",
        "df_filtered = df[df['Year'] >= 1975].copy().reset_index(drop=True)\n",
        "df_filtered.loc[:, 'Cluster'] = leiden_labels_biology['leiden'].reset_index(drop=True)\n",
        "\n",
        "# Calculate the mean year for each cluster\n",
        "mean_year_per_cluster = df_filtered.groupby('Cluster')['Year'].mean().reset_index()\n",
        "mean_year_per_cluster['Cluster_Name'] = mean_year_per_cluster['Cluster'].map(cluster_names)\n",
        "\n",
        "# Plot the mean year for each cluster\n",
        "plt.figure(figsize=(12, 8))\n",
        "mean_year_per_cluster_sorted = mean_year_per_cluster.sort_values('Year', ascending=False)\n",
        "sns.barplot(x='Year', y='Cluster_Name', data=mean_year_per_cluster_sorted, palette='RdBu')\n",
        "plt.xlabel('Mean Year of Publication')\n",
        "plt.ylabel('Cluster')\n",
        "plt.title('Mean Year of Publication per BoA Cluster')\n",
        "plt.xlim(2008, 2012)\n",
        "plt.xticks(ticks=range(2008, 2013, 2))\n",
        "plt.savefig('Mean year of publication per BoA cluster.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpGjGZ7y_Ndt"
      },
      "source": [
        "Cosine similarity trend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THcMlBgtAaI5"
      },
      "outputs": [],
      "source": [
        "# Get topic distribution for each document using LDA model\n",
        "topic_distributions = []\n",
        "for doc_bow in bow_corpus:\n",
        "    doc_topics = lda_model.get_document_topics(doc_bow, minimum_probability=0)\n",
        "    topic_vector = np.zeros(lda_model.num_topics)\n",
        "    for topic_id, prob in doc_topics:\n",
        "        topic_vector[topic_id] = prob\n",
        "    topic_distributions.append(topic_vector)\n",
        "\n",
        "df_topics = pd.DataFrame(topic_distributions)\n",
        "\n",
        "# Add cluster labels and years\n",
        "df['Leiden_Cluster'] = leiden_labels_biology['leiden']\n",
        "df_topics['Year'] = df['Year']\n",
        "df_topics['Cluster'] = df['Leiden_Cluster']\n",
        "\n",
        "# Function to calculate cosine similarity\n",
        "def cosine_similarity(v1, v2):\n",
        "    return 1 - cosine(v1, v2)\n",
        "\n",
        "# Analyze topic distributions over time within each cluster\n",
        "results = defaultdict(list)\n",
        "years = sorted(df['Year'].dropna().unique())\n",
        "\n",
        "for cluster in df['Leiden_Cluster'].unique():\n",
        "    cluster_data = df_topics[df_topics['Cluster'] == cluster]\n",
        "    for i in range(len(years) - 1):\n",
        "        year_1 = years[i]\n",
        "        year_2 = years[i + 1]\n",
        "\n",
        "        # Get average topic distribution for both years\n",
        "        dist_year_1 = cluster_data[cluster_data['Year'] == year_1].mean(axis=0).values[:-2]\n",
        "        dist_year_2 = cluster_data[cluster_data['Year'] == year_2].mean(axis=0).values[:-2]\n",
        "\n",
        "        # Compute cosine similarity between distributions\n",
        "        cosine_sim = cosine_similarity(dist_year_1, dist_year_2)\n",
        "        results[cluster].append({\n",
        "            'Year_1': year_1,\n",
        "            'Year_2': year_2,\n",
        "            'Cosine_Similarity': cosine_sim,\n",
        "        })\n",
        "\n",
        "# Convert results to DataFrame for analysis and visualization\n",
        "df_results = pd.DataFrame([\n",
        "    {'Cluster': cluster, 'Year_1': res['Year_1'], 'Year_2': res['Year_2'],\n",
        "     'Cosine_Similarity': res['Cosine_Similarity']}\n",
        "    for cluster, result in results.items() for res in result\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bidcntL7A_Di"
      },
      "outputs": [],
      "source": [
        "# Filter data from the year 1975 onwards\n",
        "df_results_filtered = df_results[df_results['Year_1'] >= 1975].copy()\n",
        "unique_clusters = sorted(df_results_filtered['Cluster'].unique())\n",
        "\n",
        "# Prepare a dictionary to store trends\n",
        "cluster_trends = {}\n",
        "\n",
        "# Iterate over each cluster to calculate the trend\n",
        "for cluster in unique_clusters:\n",
        "    cluster_data = df_results_filtered[df_results_filtered['Cluster'] == cluster].copy()\n",
        "    # Compute the 5-year moving average\n",
        "    cluster_data['Cosine_MA'] = cluster_data['Cosine_Similarity'].rolling(window=5).mean()\n",
        "    cluster_data = cluster_data.dropna(subset=['Cosine_MA'])\n",
        "\n",
        "    # Fit a linear regression model to find the slope\n",
        "    X = cluster_data['Year_1'].values.reshape(-1, 1)\n",
        "    y = cluster_data['Cosine_MA'].values\n",
        "    reg = LinearRegression().fit(X, y)\n",
        "    slope = reg.coef_[0]\n",
        "    cluster_trends[cluster_names[cluster]] = slope\n",
        "\n",
        "# Sort the clusters by trend (slope)\n",
        "sorted_trends = sorted(cluster_trends.items(), key=lambda x: x[1])\n",
        "\n",
        "# Bar plot of cosine similarity trends\n",
        "cluster_names_sorted = [item[0] for item in sorted_trends]\n",
        "slopes_sorted = [item[1] for item in sorted_trends]\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(cluster_names_sorted, slopes_sorted, color='navy')\n",
        "plt.xlabel('Trend (Slope of 5-Year Moving Average)')\n",
        "plt.ylabel('Cluster')\n",
        "plt.title('Trend of Cosine Similarity Across BoA Clusters')\n",
        "plt.savefig('Trend of Cosine Similarity Across BoA Clusters.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
