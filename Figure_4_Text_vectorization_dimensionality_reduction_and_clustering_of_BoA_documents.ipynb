{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy umap umap-learn matplotlib scikit-learn scanpy anndata igraph leidenalg collections"
      ],
      "metadata": {
        "id": "rauB-7J_kg7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scanpy as sc\n",
        "from anndata import AnnData\n",
        "import leidenalg\n",
        "import re\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "6hUPvSLlkg2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load preprocessed files"
      ],
      "metadata": {
        "id": "qxPvhQCbkftF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0pd4uVkjDdP"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/Unsupervised aging literature/LDA model docs/LDA model 4 with cleaned data/preprocessed_docs.pkl', 'rb') as f:\n",
        "    preprocessed_docs = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/Unsupervised aging literature/LDA model docs/LDA model 4 with cleaned data/bow_corpus.pkl', 'rb') as f:\n",
        "    bow_corpus = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/Unsupervised aging literature/LDA model docs/LDA model 4 with cleaned data/lda_model.pkl', 'rb') as f:\n",
        "    lda_model = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/Unsupervised aging literature/LDA model docs/LDA model 4 with cleaned data/dictionary.dict', 'rb') as f:\n",
        "    dictionary = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter documents with its main topic primarily related to the biology of aging"
      ],
      "metadata": {
        "id": "Xz9qVEhXlEfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine dominant topic for each document\n",
        "def get_dominant_topic(ldamodel, bow_corpus):\n",
        "    topics = ldamodel[bow_corpus]\n",
        "    dominant_topics = []\n",
        "    for topic_list in topics:\n",
        "        dominant_topic = sorted(topic_list, key=lambda x: x[1], reverse=True)[0][0]\n",
        "        dominant_topics.append(dominant_topic)\n",
        "    return dominant_topics\n",
        "\n",
        "dominant_topics = get_dominant_topic(lda_model, bow_corpus)\n",
        "\n",
        "# Filter documents with biology of aging related dominant topics (24, 0, 6, and 9 in our model)\n",
        "filtered_docs = [doc for doc, topic in zip(preprocessed_docs, dominant_topics) if topic in {24, 0, 6, 9}]\n",
        "\n",
        "print(f'Number of filtered documents: {len(filtered_docs)}')\n",
        "\n",
        "filtered_texts = [' '.join(doc) for doc in filtered_docs]\n",
        "\n",
        "# Save BoA filtered texts\n",
        "with open(\"filtered_docs_biology.pkl\", \"wb\") as f:\n",
        "    pickle.dump(filtered_texts, f)"
      ],
      "metadata": {
        "id": "1LJs-BM4lAYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF vectorization, PCA and UMAP of BoA documents"
      ],
      "metadata": {
        "id": "6y36FkYslaaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TF-IDF vectorizer and transform the filtered texts\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=500)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(filtered_texts)\n",
        "\n",
        "# Perform PCA on TF-IDF matrix\n",
        "pca = PCA(n_components=30)\n",
        "pca_result = pca.fit_transform(tfidf_matrix.toarray())\n",
        "\n",
        "# Perform UMAP on PCA result\n",
        "umap_model = umap.UMAP(n_neighbors=10, min_dist=0, n_components=2)\n",
        "umap_result_biology = umap_model.fit_transform(pca_result)\n",
        "\n",
        "# Plot UMAP\n",
        "plt.figure(figsize=(18, 12))\n",
        "plt.scatter(umap_result_biology[:, 0], umap_result_biology[:, 1], cmap='viridis', s=1, alpha=0.2)\n",
        "plt.title('UMAP Visualization of BoA Documents')\n",
        "plt.xlabel('UMAP Component 1')\n",
        "plt.ylabel('UMAP Component 2')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# Save UMAP embeddings\n",
        "with open(\"umap_result_biology.pkl\", \"wb\") as f:\n",
        "    pickle.dump(umap_result_biology, f)"
      ],
      "metadata": {
        "id": "uZAdzacUlail"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leiden clustering"
      ],
      "metadata": {
        "id": "7AAjWiZ6mz_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert your UMAP result into an AnnData object\n",
        "adata = AnnData(X=umap_result_biology)\n",
        "\n",
        "# Compute the k-nearest neighbors graph and run Leiden clustering\n",
        "sc.pp.neighbors(adata, n_neighbors=20, use_rep='X')\n",
        "sc.tl.leiden(adata, resolution=0.05)\n",
        "\n",
        "# Save Leiden labels\n",
        "leiden_labels_biology = adata.obs['leiden']\n",
        "leiden_labels_biology.to_csv('leiden_labels_biology.csv', index=False)\n",
        "\n",
        "# Use original UMAP coordinates for plotting\n",
        "plt.figure(figsize=(18, 12))\n",
        "scatter = plt.scatter(umap_result_biology[:, 0], umap_result_biology[:, 1], c=adata.obs['leiden'].astype('category').cat.codes, cmap='tab20', s=0.5, alpha=0.2)\n",
        "plt.colorbar(scatter, ticks=range(len(adata.obs['leiden'].unique())))\n",
        "plt.title(\"UMAP with Leiden Clusters\")\n",
        "plt.xlabel(\"UMAP 1\")\n",
        "plt.ylabel(\"UMAP 2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Pv6pXUHHluUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate top 10 differential words between clusters based on TF-IDF score"
      ],
      "metadata": {
        "id": "1iITC8AsnaLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
        "tfidf_df['cluster'] = adata.obs['leiden'].astype(int).values\n",
        "\n",
        "# Compute mean TF-IDF scores for each word within each cluster\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
        "tfidf_df['cluster'] = adata.obs['leiden'].astype(int).values\n",
        "cluster_means = tfidf_df.groupby('cluster').mean()\n",
        "differential_scores = {}\n",
        "for cluster in cluster_means.index:\n",
        "    other_clusters = cluster_means.drop(index=cluster)\n",
        "    differential_scores[cluster] = cluster_means.loc[cluster] - other_clusters.max()\n",
        "\n",
        "# Get the top N differential words for each cluster\n",
        "N = 10\n",
        "top_differential_words = {}\n",
        "\n",
        "for cluster in differential_scores:\n",
        "    sorted_terms = differential_scores[cluster].sort_values(ascending=False)\n",
        "    top_differential_words[cluster] = sorted_terms.head(N).index.tolist()\n",
        "\n",
        "# Convert each word to a string enclosed in single quotes for each cluster\n",
        "top_differential_words_biology = {\n",
        "    cluster: [f\"'{word}'\" for word in words] for cluster, words in top_differential_words.items()\n",
        "}\n",
        "\n",
        "top_differential_words_biology_df = pd.DataFrame(top_differential_words_biology).transpose()\n",
        "top_differential_words_biology_df.columns = [f\"Top {i+1}\" for i in range(len(top_differential_words_biology_df.columns))]\n",
        "top_differential_words_biology_df.to_csv('top_differential_words_biology.csv', index=True)"
      ],
      "metadata": {
        "id": "aXH1c0fcnWz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the presence of top 3 differential words (stems) of each cluster in every cluster"
      ],
      "metadata": {
        "id": "wSHChmV8nQR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_docs = [str(doc) for doc in filtered_docs]\n",
        "\n",
        "# Define the word groups for each cluster\n",
        "word_groups = {\n",
        "    0: ['receptor', 'rat', 'hormon'],\n",
        "    1: ['oxid', 'stress', 'peroxid'],\n",
        "    2: ['arrest', 'cycl', 'senesc'],\n",
        "    3: ['factor', 'oocyt', 'inflammatori'],\n",
        "    4: ['immun', 'infect', 'antibodi'],\n",
        "    5: ['mitochondri', 'mitochondria', 'mtdna'],\n",
        "    6: ['mice', 'app', 'transgen'],\n",
        "    7: ['mutat', 'genet', 'famili'],\n",
        "    8: ['cell', 'stem', 'adult'],\n",
        "    9: ['cancer', 'tumor', 'lung'],\n",
        "    10: ['protein', 'lifespan', 'kinas'],\n",
        "    11: ['gene', 'express', 'transcript'],\n",
        "    12: ['beta', 'alpha', 'tgf'],\n",
        "    13: ['neuron', 'astrocyt', 'hippocamp'],\n",
        "    14: ['repair', 'dna', 'damag'],\n",
        "    15: ['bone', 'msc', 'marrow'],\n",
        "    16: ['muscl', 'synthesi', 'bodi'],\n",
        "    17: ['telomer', 'telomeras', 'length'],\n",
        "    18: ['target', 'overexpress', 'downregul'],\n",
        "    19: ['methyl', 'epigenet', 'chang'],\n",
        "    20: ['autophagi', 'degrad', 'process'],\n",
        "    21: ['sirt', 'mammalian', 'glucos'],\n",
        "    22: ['skin', 'mmp', 'protect']\n",
        "}\n",
        "\n",
        "# Define cluster names\n",
        "cluster_names = {\n",
        "    0: 'Cell signaling',\n",
        "    1: 'Oxidative stress',\n",
        "    2: 'Senescence',\n",
        "    3: 'Cell & molecular biology',\n",
        "    4: 'Immunology',\n",
        "    5: 'Mitochondria',\n",
        "    6: 'Alzheimer\\'s',\n",
        "    7: 'Genetics (clinical)',\n",
        "    8: 'Stem cells',\n",
        "    9: 'Cancer',\n",
        "    10: 'Protein biology',\n",
        "    11: 'Genetics (biology)',\n",
        "    12: 'Growth factors and cytokines',\n",
        "    13: 'Neuroscience',\n",
        "    14: 'Genomic stability',\n",
        "    15: 'Mesenchymal stem cells',\n",
        "    16: 'Muscle',\n",
        "    17: 'Telomeres',\n",
        "    18: 'RNA biology',\n",
        "    19: 'Epigenetics',\n",
        "    20: 'Autophagy',\n",
        "    21: 'Sirtuins, mTOR and caloric restriction',\n",
        "    22: 'Skin'\n",
        "}\n",
        "\n",
        "\n",
        "# Function to check for the presence of each word\n",
        "unique_words = list(set(word for words_list in word_groups.values() for word in words_list))\n",
        "word_presence_matrix = pd.DataFrame(0, index=cluster_names.values(), columns=word_groups.keys())\n",
        "def check_word_group_presence(doc, word_group):\n",
        "    return any(re.search(r'\\b' + word + r'\\b', doc) for word in word_group)\n",
        "\n",
        "# Combine the necessary data by using the 'leiden' column from leiden_labels_biology\n",
        "preprocessed_docs_df = pd.DataFrame(filtered_docs, columns=['Abstract'])\n",
        "if len(preprocessed_docs_df) != len(leiden_labels_biology):\n",
        "    raise ValueError(\"The lengths of preprocessed_docs and leiden_labels_biology do not match!\")\n",
        "preprocessed_docs_df['leiden'] = leiden_labels_biology['leiden'].values\n",
        "\n",
        "# Ensure all entries in the 'Abstract' column are strings\n",
        "preprocessed_docs_df['Abstract'] = preprocessed_docs_df['Abstract'].astype(str)\n",
        "\n",
        "# Process the documents to check for word group presence\n",
        "for cluster, cluster_name in cluster_names.items():\n",
        "    cluster_docs = preprocessed_docs_df[preprocessed_docs_df['leiden'] == cluster]['Abstract']\n",
        "    total_docs_in_cluster = len(cluster_docs)\n",
        "    for group, words in word_groups.items():\n",
        "        word_group_presence_count = sum(check_word_group_presence(doc, words) for doc in cluster_docs)\n",
        "        word_presence_matrix.at[cluster_name, group] = word_group_presence_count / total_docs_in_cluster if total_docs_in_cluster > 0 else 0"
      ],
      "metadata": {
        "id": "5L96Ibi1pkUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the heatmap\n",
        "x_labels = [', '.join([word.capitalize() for word in group]) for group in word_groups.values()]\n",
        "word_presence_matrix = word_presence_matrix.sort_index(axis=1)\n",
        "\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.heatmap(word_presence_matrix, cmap='RdBu_r', cbar=True, annot=False)\n",
        "plt.ylabel('Clusters', fontsize=20)\n",
        "plt.xlabel('Top Differential Words', fontsize=20)\n",
        "plt.title('Top Differential Words Presence in Clusters', fontsize=20)\n",
        "plt.xticks(ticks=np.arange(len(x_labels))+0.5, labels=x_labels, rotation=90, fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "plt.savefig('Heatmap of Word Presence in BoA Clusters.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vn5qMLYDqWGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate and plot number of documents per cluster"
      ],
      "metadata": {
        "id": "h2j117mkqona"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert UMAP results to a DataFrame\n",
        "umap_df = pd.DataFrame(umap_result_biology, columns=['UMAP1', 'UMAP2'])\n",
        "\n",
        "# Add leiden labels to the combined dataframe\n",
        "combined_df = pd.concat([umap_df, leiden_labels_biology], axis=1)\n",
        "\n",
        "# Replace cluster numbers with names\n",
        "combined_df['Cluster Name'] = combined_df['leiden'].map(cluster_names)\n",
        "\n",
        "# Count the number of documents per cluster\n",
        "cluster_counts = combined_df['Cluster Name'].value_counts().reset_index()\n",
        "cluster_counts.columns = ['Cluster Name', 'Count']\n",
        "cluster_counts = cluster_counts.sort_values(by='Count', ascending=False)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(24, 16))\n",
        "sns.barplot(data=cluster_counts, x='Cluster Name', y='Count', palette='RdBu')\n",
        "plt.xticks(rotation=90, fontsize=18)\n",
        "plt.yticks(fontsize=18, fontfamily='serif')\n",
        "plt.title('Number of Documents per Cluster', fontsize=28)\n",
        "plt.ylabel('Number of Documents', fontsize=24)\n",
        "plt.xlabel('')\n",
        "plt.savefig('Number of Documents per BoA Cluster.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SR8zhJwyqlxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine similarity"
      ],
      "metadata": {
        "id": "M6CFyY8Rq-6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign TF-IDF vectors to clusters based on leiden labels\n",
        "leiden_labels_biology['tfidf'] = list(tfidf_matrix.toarray())\n",
        "\n",
        "# Group by cluster labels and compute the mean TF-IDF vector for each cluster\n",
        "cluster_tfidf = leiden_labels_biology.groupby('leiden')['tfidf'].apply(lambda x: np.mean(np.stack(x.values), axis=0))\n",
        "\n",
        "# Compute cosine similarity matrix between cluster mean TF-IDF vectors\n",
        "cos_sim_matrix = cosine_similarity(np.stack(cluster_tfidf.values))\n",
        "valid_clusters = [label for label in cluster_tfidf.index if label in cluster_names]\n",
        "cluster_tfidf = cluster_tfidf[valid_clusters]\n",
        "\n",
        "# Create the cosine similarity DataFrame with correct labels\n",
        "cos_sim_df = pd.DataFrame(cos_sim_matrix, index=[cluster_names[label] for label in valid_clusters], columns=[cluster_names[label] for label in valid_clusters])\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.heatmap(cos_sim_df, annot=False, cmap='RdBu_r')\n",
        "plt.title('Cosine Similarity Between Clusters Based on TF-IDF', fontsize=20)\n",
        "plt.ylabel('Clusters', fontsize=20)\n",
        "plt.xlabel('Clusters', fontsize=20)\n",
        "plt.xticks(rotation=90, fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "plt.savefig('Cosine Similarity Heatmap BoA.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qAlHX0hWq9oF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Presence of the Hallmarks of Aging in each cluster"
      ],
      "metadata": {
        "id": "K2mpoQf7r64K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Words of interest (stems)\n",
        "words = ['oxid', 'senesc', 'inflamm', 'mitochondri', 'genom', 'stem',\n",
        "         'intercellular', 'telomer', 'epigenet', 'autophagi', 'mammalian', 'metabol', 'nutrient', 'microbi']\n",
        "\n",
        "# Replace cluster labels with their corresponding names\n",
        "df['Cluster'] = df['Cluster'].map(cluster_names)\n",
        "\n",
        "# Count the presence of each word in each cluster and calculate the percentage of documents containing that word in each cluster\n",
        "word_presence = {cluster: [0] * len(words) for cluster in df['Cluster'].unique()}\n",
        "for cluster in df['Cluster'].unique():\n",
        "    cluster_docs = df[df['Cluster'] == cluster]['Document']\n",
        "    for word in words:\n",
        "        count = sum(word in doc for doc in cluster_docs)\n",
        "        word_presence[cluster][words.index(word)] = count\n",
        "\n",
        "cluster_doc_count = df['Cluster'].value_counts().to_dict()\n",
        "data = []\n",
        "for cluster, counts in word_presence.items():\n",
        "    total_docs = cluster_doc_count.get(cluster, 1)\n",
        "    percentages = (counts / total_docs) * 100\n",
        "    for word, percentage in zip(words, percentages):\n",
        "        data.append([cluster, word, percentage])\n",
        "df_plot = pd.DataFrame(data, columns=['Cluster', 'Word', 'Percentage'])\n",
        "df_plot['Cluster'] = pd.Categorical(df_plot['Cluster'], categories=cluster_names.values(), ordered=True)\n",
        "print(df_plot.head())"
      ],
      "metadata": {
        "id": "cJt7eB57sCRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Capitalize the words in df_plot for plotting\n",
        "df_plot['Word'] = df_plot['Word'].str.capitalize()\n",
        "\n",
        "# Create a color gradient for the 'Percentage' column\n",
        "norm = plt.Normalize(df_plot['Percentage'].min(), df_plot['Percentage'].max())\n",
        "cmap = sns.color_palette(\"RdBu_r\", as_cmap=True)\n",
        "\n",
        "# Create a column in the original dataframe for color coding based on 'Percentage'\n",
        "df_plot['Color'] = df_plot['Percentage'].apply(lambda x: cmap(norm(x)))\n",
        "\n",
        "# Plotting the dot plot with a color gradient and sizes proportional to percentages\n",
        "plt.figure(figsize=(15, 10))\n",
        "ax = sns.scatterplot(\n",
        "    data=df_plot,\n",
        "    x='Word',\n",
        "    y='Cluster',\n",
        "    size='Percentage',\n",
        "    legend=False,\n",
        "    sizes=(20, 400),\n",
        "    hue='Percentage',\n",
        "    palette=cmap,\n",
        "    alpha=0.8\n",
        ")\n",
        "\n",
        "def replace_mtor(label):\n",
        "    if label == 'Mammalian':\n",
        "        return 'Mammalian (mTOR)'\n",
        "    return label\n",
        "new_labels = [replace_mtor(label.get_text()) for label in ax.get_xticklabels()]\n",
        "\n",
        "ax.set_xticklabels(new_labels, rotation=90, fontsize=12)\n",
        "ax.set_xlabel('Word', fontsize=16)\n",
        "ax.set_ylabel('Cluster', fontsize=16)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.title('Presence of the Hallmarks of Aging in each Cluster', fontsize=18)\n",
        "plt.tight_layout()\n",
        "plt.savefig('Hallmarks of Aging in BoA Clusters.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QWpul1hTtvAw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
