{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rauB-7J_kg7Z"
      },
      "outputs": [],
      "source": [
        "! pip install pandas==2.2.2 numpy==1.24.4 umap==0.1.1 umap-learn==0.5.7 scipy==1.13.1 scikit-learn==1.5.2 matplotlib==3.10.0 seaborn==0.13.2 scanpy==1.11.1 anndata==0.11.4 igraph==0.11.8 leidenalg==0.10.2 gensim==4.3.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hUPvSLlkg2H"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scanpy as sc\n",
        "from anndata import AnnData\n",
        "import leidenalg\n",
        "import re\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxPvhQCbkftF"
      },
      "source": [
        "Load preprocessed files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0pd4uVkjDdP"
      },
      "outputs": [],
      "source": [
        "with open('preprocessed_docs.pkl', 'rb') as f:\n",
        "    preprocessed_docs = pickle.load(f)\n",
        "\n",
        "with open('bow_corpus.pkl', 'rb') as f:\n",
        "    bow_corpus = pickle.load(f)\n",
        "\n",
        "with open('lda_model.pkl', 'rb') as f:\n",
        "    lda_model = pickle.load(f)\n",
        "\n",
        "with open('dictionary.dict', 'rb') as f:\n",
        "    dictionary = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz9qVEhXlEfX"
      },
      "source": [
        "Filter documents with its main topic primarily related to the biology of aging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LJs-BM4lAYO"
      },
      "outputs": [],
      "source": [
        "# Determine dominant topic for each document\n",
        "def get_dominant_topic(ldamodel, bow_corpus):\n",
        "    topics = ldamodel[bow_corpus]\n",
        "    dominant_topics = []\n",
        "    for topic_list in topics:\n",
        "        dominant_topic = sorted(topic_list, key=lambda x: x[1], reverse=True)[0][0]\n",
        "        dominant_topics.append(dominant_topic)\n",
        "    return dominant_topics\n",
        "\n",
        "dominant_topics = get_dominant_topic(lda_model, bow_corpus)\n",
        "\n",
        "# Filter documents with biology of aging related dominant topics (24, 0, 6, and 9 in our model)\n",
        "filtered_docs = [doc for doc, topic in zip(preprocessed_docs, dominant_topics) if topic in {24, 0, 6, 9}]\n",
        "\n",
        "print(f'Number of filtered documents: {len(filtered_docs)}')\n",
        "\n",
        "filtered_texts = [' '.join(doc) for doc in filtered_docs]\n",
        "\n",
        "# Save BoA filtered texts\n",
        "with open(\"filtered_docs_biology.pkl\", \"wb\") as f:\n",
        "    pickle.dump(filtered_texts, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y36FkYslaaR"
      },
      "source": [
        "TF-IDF vectorization, PCA and UMAP of BoA documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZAdzacUlail"
      },
      "outputs": [],
      "source": [
        "# Create TF-IDF vectorizer and transform the filtered texts\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=500)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(filtered_texts)\n",
        "\n",
        "# Perform PCA on TF-IDF matrix\n",
        "pca = PCA(n_components=30)\n",
        "pca_result = pca.fit_transform(tfidf_matrix.toarray())\n",
        "\n",
        "# Perform UMAP on PCA result\n",
        "umap_model = umap.UMAP(n_neighbors=10, min_dist=0, n_components=2)\n",
        "umap_result_biology = umap_model.fit_transform(pca_result)\n",
        "\n",
        "# Plot UMAP\n",
        "plt.figure(figsize=(18, 12))\n",
        "plt.scatter(umap_result_biology[:, 0], umap_result_biology[:, 1], cmap='viridis', s=1, alpha=0.2)\n",
        "plt.title('UMAP Visualization of BoA Documents')\n",
        "plt.xlabel('UMAP Component 1')\n",
        "plt.ylabel('UMAP Component 2')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# Save UMAP embeddings\n",
        "with open(\"umap_result_biology.pkl\", \"wb\") as f:\n",
        "    pickle.dump(umap_result_biology, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AAjWiZ6mz_f"
      },
      "source": [
        "Leiden clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv6pXUHHluUf"
      },
      "outputs": [],
      "source": [
        "# Convert your PCA result into an AnnData object\n",
        "adata = AnnData(X=pca_result)\n",
        "\n",
        "# Compute the k-nearest neighbors graph and run Leiden clustering\n",
        "sc.pp.neighbors(adata, n_neighbors=5, use_rep='X')\n",
        "sc.tl.leiden(adata, resolution=0.7)\n",
        "\n",
        "# Save Leiden labels\n",
        "leiden_labels_biology = adata.obs['leiden']\n",
        "leiden_labels_biology.to_csv('leiden_labels_biology.csv', index=False)\n",
        "\n",
        "# Use original UMAP coordinates for plotting\n",
        "plt.figure(figsize=(18, 12))\n",
        "scatter = plt.scatter(umap_result_biology[:, 0], umap_result_biology[:, 1], c=adata.obs['leiden'].astype('category').cat.codes, cmap='tab20', s=0.5, alpha=0.2)\n",
        "plt.colorbar(scatter, ticks=range(len(adata.obs['leiden'].unique())))\n",
        "plt.title(\"UMAP with Leiden Clusters\")\n",
        "plt.xlabel(\"UMAP 1\")\n",
        "plt.ylabel(\"UMAP 2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iITC8AsnaLP"
      },
      "source": [
        "Calculate top 10 differential words between clusters based on TF-IDF score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXH1c0fcnWz5"
      },
      "outputs": [],
      "source": [
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
        "tfidf_df['cluster'] = adata.obs['leiden'].astype(int).values\n",
        "\n",
        "# Compute mean TF-IDF scores for each word within each cluster\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
        "tfidf_df['cluster'] = adata.obs['leiden'].astype(int).values\n",
        "cluster_means = tfidf_df.groupby('cluster').mean()\n",
        "differential_scores = {}\n",
        "for cluster in cluster_means.index:\n",
        "    other_clusters = cluster_means.drop(index=cluster)\n",
        "    differential_scores[cluster] = cluster_means.loc[cluster] - other_clusters.max()\n",
        "\n",
        "# Get the top N differential words for each cluster\n",
        "N = 10\n",
        "top_differential_words = {}\n",
        "\n",
        "for cluster in differential_scores:\n",
        "    sorted_terms = differential_scores[cluster].sort_values(ascending=False)\n",
        "    top_differential_words[cluster] = sorted_terms.head(N).index.tolist()\n",
        "\n",
        "# Convert each word to a string enclosed in single quotes for each cluster\n",
        "top_differential_words_biology = {\n",
        "    cluster: [f\"'{word}'\" for word in words] for cluster, words in top_differential_words.items()\n",
        "}\n",
        "\n",
        "top_differential_words_biology_df = pd.DataFrame(top_differential_words_biology).transpose()\n",
        "top_differential_words_biology_df.columns = [f\"Top {i+1}\" for i in range(len(top_differential_words_biology_df.columns))]\n",
        "top_differential_words_biology_df.to_csv('top_differential_words_biology.csv', index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSHChmV8nQR5"
      },
      "source": [
        "Calculate the presence of top 3 differential words (stems) of each cluster in every cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5L96Ibi1pkUZ"
      },
      "outputs": [],
      "source": [
        "filtered_docs = [str(doc) for doc in filtered_docs]\n",
        "\n",
        "# Load the CSV file with leiden labels\n",
        "leiden_labels_biology = pd.read_csv('leiden_labels_biology.csv')\n",
        "\n",
        "# Define the word groups for each cluster\n",
        "word_groups = {\n",
        "    0: ['variant', 'genet', 'allel'],\n",
        "    1: ['gene', 'express', 'transcript'],\n",
        "    2: ['cancer', 'tumor', 'line'],\n",
        "    3: ['methyl', 'epigenet', 'modif'],\n",
        "    4: ['insulin', 'igf', 'lifespan'],\n",
        "    5: ['oxid', 'stress', 'antioxid'],\n",
        "    6: ['stem', 'embryon', 'progenitor'],\n",
        "    7: ['bone', 'msc', 'marrow'],\n",
        "    8: ['transgen', 'mous', 'model'],\n",
        "    9: ['activ', 'enzym', 'rat'],\n",
        "    10: ['neuron', 'astrocyt', 'brain'],\n",
        "    11: ['young', 'old', 'mice'],\n",
        "    12: ['skin', 'mmp', 'inflammatori'],\n",
        "    13: ['lymphocyt', 'immun', 'infect'],\n",
        "    14: ['mutat', 'patient', 'caus'],\n",
        "    15: ['mitochondri', 'atp', 'mtdna'],\n",
        "    16: ['protein', 'domain', 'interact'],\n",
        "    17: ['senesc', 'cellular', 'arrest'],\n",
        "    18: ['dna', 'repair', 'damag'],\n",
        "    19: ['beta', 'app', 'amyloid'],\n",
        "    20: ['muscl', 'skelet', 'mass'],\n",
        "    21: ['mir', 'mirna', 'target'],\n",
        "    22: ['receptor', 'bind', 'densiti'],\n",
        "    23: ['alpha', 'subunit', 'tnf'],\n",
        "    24: ['telomer', 'telomeras', 'length'],\n",
        "    25: ['sirt', 'mammalian', 'delai'],\n",
        "    26: ['autophagi', 'degrad', 'homeostasi']\n",
        "}\n",
        "\n",
        "# Define cluster names\n",
        "cluster_names = {\n",
        "    0: 'GWAS',\n",
        "    1: 'Gene regulation',\n",
        "    2: 'Cancer',\n",
        "    3: 'Epigenetics',\n",
        "    4: 'Insulin/IGF pathway',\n",
        "    5: 'Oxidative stress',\n",
        "    6: 'Stem cells',\n",
        "    7: 'Mesenchymal stem cells',\n",
        "    8: 'Mouse models',\n",
        "    9: 'Biochemistry',\n",
        "    10: 'Neuroscience',\n",
        "    11: 'Comparative studies',\n",
        "    12: 'Skin',\n",
        "    13: 'Immunology',\n",
        "    14: 'Clinical genetics',\n",
        "    15: 'Mitochondria',\n",
        "    16: 'Protein biology',\n",
        "    17: 'Senescence',\n",
        "    18: 'Genomic stability',\n",
        "    19: \"Alzheimer's\",\n",
        "    20: 'Muscle',\n",
        "    21: 'RNA biology',\n",
        "    22: 'Receptor biology',\n",
        "    23: 'Cytokines',\n",
        "    24: 'Telomeres',\n",
        "    25: 'Sirtuins & mTOR',\n",
        "    26: 'Autophagy'\n",
        "}\n",
        "\n",
        "# Function to check for the presence of each word\n",
        "unique_words = list(set(word for words_list in word_groups.values() for word in words_list))\n",
        "word_presence_matrix = pd.DataFrame(0, index=cluster_names.values(), columns=word_groups.keys())\n",
        "def check_word_group_presence(doc, word_group):\n",
        "    return any(re.search(r'\\b' + word + r'\\b', doc) for word in word_group)\n",
        "\n",
        "# Combine the necessary data by using the 'leiden' column from leiden_labels_biology\n",
        "preprocessed_docs_df = pd.DataFrame(filtered_docs, columns=['Abstract'])\n",
        "if len(preprocessed_docs_df) != len(leiden_labels_biology):\n",
        "    raise ValueError(\"The lengths of preprocessed_docs and leiden_labels_biology do not match!\")\n",
        "preprocessed_docs_df['leiden'] = leiden_labels_biology['leiden'].values\n",
        "\n",
        "# Ensure all entries in the 'Abstract' column are strings\n",
        "preprocessed_docs_df['Abstract'] = preprocessed_docs_df['Abstract'].astype(str)\n",
        "\n",
        "# Process the documents to check for word group presence\n",
        "for cluster, cluster_name in cluster_names.items():\n",
        "    cluster_docs = preprocessed_docs_df[preprocessed_docs_df['leiden'] == cluster]['Abstract']\n",
        "    total_docs_in_cluster = len(cluster_docs)\n",
        "    for group, words in word_groups.items():\n",
        "        word_group_presence_count = sum(check_word_group_presence(doc, words) for doc in cluster_docs)\n",
        "        word_presence_matrix.at[cluster_name, group] = word_group_presence_count / total_docs_in_cluster if total_docs_in_cluster > 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn5qMLYDqWGX"
      },
      "outputs": [],
      "source": [
        "# Calculate document counts per cluster\n",
        "cluster_doc_counts = preprocessed_docs_df['leiden'].value_counts()\n",
        "sorted_cluster_ids = cluster_doc_counts.sort_values(ascending=False).index.tolist()\n",
        "\n",
        "# Sort the word_presence_matrix rows by cluster name using sorted cluster IDs\n",
        "sorted_cluster_names = [cluster_names[i] for i in sorted_cluster_ids]\n",
        "word_presence_matrix_sorted = word_presence_matrix.loc[sorted_cluster_names]\n",
        "\n",
        "# Reorder the columns to match the sorted clusters\n",
        "sorted_columns = sorted_cluster_ids\n",
        "word_presence_matrix_sorted = word_presence_matrix_sorted[sorted_columns]\n",
        "\n",
        "# Create sorted x-axis labels\n",
        "x_labels = [', '.join([word.capitalize() for word in word_groups[i]]) for i in sorted_columns]\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.heatmap(word_presence_matrix_sorted, cmap='RdBu_r', cbar=True, annot=False)\n",
        "plt.ylabel('Clusters', fontsize=20)\n",
        "plt.xlabel('Top Differential Words', fontsize=24)\n",
        "plt.title('Top Differential Words Presence in BoA Clusters', fontsize=24)\n",
        "plt.xticks(ticks=np.arange(len(x_labels)) + 0.5, labels=x_labels, rotation=90, fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.savefig('Heatmap of Word Presence in BoA Clusters.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2j117mkqona"
      },
      "source": [
        "Calculate and plot number of documents per cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR8zhJwyqlxD"
      },
      "outputs": [],
      "source": [
        "# Convert UMAP results to a DataFrame\n",
        "umap_df = pd.DataFrame(umap_result_biology, columns=['UMAP1', 'UMAP2'])\n",
        "\n",
        "# Add leiden labels to the combined dataframe\n",
        "combined_df = pd.concat([umap_df, leiden_labels_biology], axis=1)\n",
        "\n",
        "# Replace cluster numbers with names\n",
        "combined_df['Cluster Name'] = combined_df['leiden'].map(cluster_names)\n",
        "\n",
        "# Count the number of documents per cluster\n",
        "cluster_counts = combined_df['Cluster Name'].value_counts().reset_index()\n",
        "cluster_counts.columns = ['Cluster Name', 'Count']\n",
        "cluster_counts = cluster_counts.sort_values(by='Count', ascending=False)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(24, 16))\n",
        "sns.barplot(data=cluster_counts, x='Cluster Name', y='Count', palette='RdBu')\n",
        "plt.xticks(rotation=90, fontsize=28)\n",
        "plt.yticks(fontsize=28, fontfamily='serif')\n",
        "plt.title('Number of Documents per BoA Cluster', fontsize=32)\n",
        "plt.ylabel('Number of Documents', fontsize=28)\n",
        "plt.xlabel('')\n",
        "plt.savefig('Number of Documents per BoA Cluster.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6CFyY8Rq-6q"
      },
      "source": [
        "Cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAlHX0hWq9oF"
      },
      "outputs": [],
      "source": [
        "# Assign TF-IDF vectors to clusters based on leiden labels\n",
        "leiden_labels_biology['tfidf'] = list(tfidf_matrix.toarray())\n",
        "\n",
        "# Group by cluster labels and compute the mean TF-IDF vector for each cluster\n",
        "cluster_tfidf = leiden_labels_biology.groupby('leiden')['tfidf'].apply(lambda x: np.mean(np.stack(x.values), axis=0))\n",
        "\n",
        "# Get cluster document counts and sort cluster IDs descending\n",
        "cluster_doc_counts = preprocessed_docs_df['leiden'].value_counts()\n",
        "sorted_cluster_ids = cluster_doc_counts.sort_values(ascending=False).index.tolist()\n",
        "sorted_cluster_ids = [cid for cid in sorted_cluster_ids if cid in cluster_tfidf.index]\n",
        "\n",
        "# Reorder the cluster_tfidf and compute cosine similarity matrix between TF-IDF vectors\n",
        "cluster_tfidf_sorted = cluster_tfidf.loc[sorted_cluster_ids]\n",
        "cos_sim_matrix_sorted = cosine_similarity(np.stack(cluster_tfidf_sorted.values))\n",
        "\n",
        "# Build the sorted similarity DataFrame with cluster names\n",
        "sorted_cluster_names = [cluster_names[cid] for cid in sorted_cluster_ids]\n",
        "cos_sim_df_sorted = pd.DataFrame(\n",
        "    cos_sim_matrix_sorted,\n",
        "    index=sorted_cluster_names,\n",
        "    columns=sorted_cluster_names\n",
        ")\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.heatmap(cos_sim_df_sorted, annot=False, cmap='RdBu_r')\n",
        "plt.title('Cosine Similarity Between BoA Clusters Based on TF-IDF', fontsize=24)\n",
        "plt.ylabel('Clusters', fontsize=20)\n",
        "plt.xlabel('Clusters', fontsize=20)\n",
        "plt.xticks(rotation=90, fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.savefig('Cosine Similarity Heatmap BoA.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2mpoQf7r64K"
      },
      "source": [
        "Presence of the Hallmarks of Aging in each cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJt7eB57sCRc"
      },
      "outputs": [],
      "source": [
        "# Words of interest (stems)\n",
        "words = ['oxid', 'inflamm', 'senesc', 'mitochondri', 'genom', 'stem', 'insulin', 'metabol',\n",
        "        'telomer', 'epigenet', 'autophagi', 'nutrient', 'microbi', 'intercellular']\n",
        "\n",
        "# Replace cluster labels with their corresponding names\n",
        "preprocessed_docs_df['Cluster'] = preprocessed_docs_df['leiden'].map(cluster_names)\n",
        "\n",
        "# Count the presence of each word in each cluster and calculate the percentage of documents containing that word in each cluster\n",
        "word_presence = {cluster: [0] * len(words) for cluster in preprocessed_docs_df['Cluster'].unique()}\n",
        "for cluster in preprocessed_docs_df['Cluster'].unique():\n",
        "    cluster_docs = preprocessed_docs_df[preprocessed_docs_df['Cluster'] == cluster]['Abstract']\n",
        "    for word in words:\n",
        "        count = sum(word in doc for doc in cluster_docs)\n",
        "        word_presence[cluster][words.index(word)] = count\n",
        "\n",
        "cluster_doc_count = preprocessed_docs_df['Cluster'].value_counts().to_dict()\n",
        "data = []\n",
        "for cluster, counts in word_presence.items():\n",
        "    total_docs = cluster_doc_count.get(cluster, 1)\n",
        "    percentages = (np.array(counts) / total_docs) * 100\n",
        "    for word, percentage in zip(words, percentages):\n",
        "        data.append([cluster, word, percentage])\n",
        "df_plot = pd.DataFrame(data, columns=['Cluster', 'Word', 'Percentage'])\n",
        "df_plot['Cluster'] = pd.Categorical(df_plot['Cluster'], categories=cluster_names.values(), ordered=True)\n",
        "print(df_plot.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWpul1hTtvAw"
      },
      "outputs": [],
      "source": [
        "# Get doc counts per cluster ID and sort descending\n",
        "cluster_doc_counts = preprocessed_docs_df['leiden'].value_counts()\n",
        "\n",
        "# Map cluster IDs to names\n",
        "cluster_id_to_name = cluster_names\n",
        "cluster_name_order = [cluster_id_to_name[cid] for cid in cluster_doc_counts.index if cid in cluster_id_to_name]\n",
        "df_plot['Cluster'] = pd.Categorical(df_plot['Cluster'], categories=cluster_name_order, ordered=True)\n",
        "\n",
        "# Capitalize words\n",
        "df_plot['Word'] = df_plot['Word'].str.capitalize()\n",
        "\n",
        "# Color gradient based on percentage of documents containing each stem\n",
        "norm = plt.Normalize(df_plot['Percentage'].min(), df_plot['Percentage'].max())\n",
        "cmap = sns.color_palette(\"RdBu_r\", as_cmap=True)\n",
        "df_plot['Color'] = df_plot['Percentage'].apply(lambda x: cmap(norm(x)))\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(20, 15))\n",
        "ax = sns.scatterplot(\n",
        "    data=df_plot,\n",
        "    x='Word',\n",
        "    y='Cluster',\n",
        "    size='Percentage',\n",
        "    legend=False,\n",
        "    sizes=(20, 400),\n",
        "    hue='Percentage',\n",
        "    palette=cmap,\n",
        "    alpha=0.8\n",
        ")\n",
        "\n",
        "# Optional label tweak\n",
        "def replace_mtor(label):\n",
        "    if label == 'Mammalian':\n",
        "        return 'Mammalian (mTOR)'\n",
        "    return label\n",
        "\n",
        "new_labels = [replace_mtor(label.get_text()) for label in ax.get_xticklabels()]\n",
        "ax.set_xticklabels(new_labels, rotation=90, fontsize=12)\n",
        "\n",
        "ax.set_xlabel('Word', fontsize=26)\n",
        "ax.set_ylabel('BoA Cluster', fontsize=26)\n",
        "plt.yticks(fontsize=22)\n",
        "plt.xticks(fontsize=22)\n",
        "plt.title('Presence of the Hallmarks of Aging in each BoA Cluster', fontsize=28)\n",
        "plt.tight_layout()\n",
        "plt.savefig('Hallmarks of Aging in BoA Clusters.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
