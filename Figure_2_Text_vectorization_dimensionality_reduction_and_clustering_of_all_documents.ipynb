{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install pandas numpy umap umap-learn scipy sklearn matplotlib seaborn scanpy anndata igraph ledenalg"
      ],
      "metadata": {
        "id": "OYi5YfduZcgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "import scanpy as sc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from anndata import AnnData\n",
        "import leidenalg\n",
        "import seaborn as sns\n",
        "import re\n",
        "from scipy.stats import fisher_exact"
      ],
      "metadata": {
        "id": "Sh_AdxVEZdHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load preprocessed files"
      ],
      "metadata": {
        "id": "iNlFYxX5aZ2i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('lda_model.pkl', 'rb') as f:\n",
        "    lda_model = pickle.load(f)\n",
        "\n",
        "with open('preprocessed_docs.pkl', 'rb') as f:\n",
        "    preprocessed_docs = pickle.load(f)\n",
        "\n",
        "with open('bow_corpus.pkl', 'rb') as f:\n",
        "    bow_corpus = pickle.load(f)\n",
        "\n",
        "with open('dictionary.dict', 'rb') as f:\n",
        "    dictionary = pickle.load(f)"
      ],
      "metadata": {
        "id": "RPqA0LO8ZdJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF vectorization, PCA and UMAP of all documents"
      ],
      "metadata": {
        "id": "kId5q7HdZCof"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGyA9i6VXjG2"
      },
      "outputs": [],
      "source": [
        "# Convert preprocessed documents back to text\n",
        "preprocessed_texts = preprocessed_docs.apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Create TF-IDF matrix\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=500)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_texts)\n",
        "\n",
        "# Perform PCA on TF-IDF matrix\n",
        "pca = PCA(n_components=50)\n",
        "pca_result = pca.fit_transform(tfidf_matrix.toarray())\n",
        "\n",
        "# Perform UMAP on PCA result\n",
        "umap_model = umap.UMAP(n_neighbors=5, min_dist=0, n_components=2)\n",
        "umap_result = umap_model.fit_transform(pca_result)\n",
        "\n",
        "# Plot UMAP\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(umap_result[:, 0], umap_result[:, 1], cmap='viridis', s=1, alpha=0.2)\n",
        "plt.title('UMAP Visualization of Documents')\n",
        "plt.xlabel('UMAP 1')\n",
        "plt.ylabel('UMAP 2')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# Save UMAP embeddings\n",
        "with open(\"umap_result.pkl\", \"wb\") as f:\n",
        "    pickle.dump(umap_result, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leiden clustering"
      ],
      "metadata": {
        "id": "o_7QFf1_a-56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert your UMAP result into an AnnData object\n",
        "adata = AnnData(X=umap_result)\n",
        "\n",
        "# Compute the k-nearest neighbors graph and run Leiden clustering\n",
        "sc.pp.neighbors(adata, n_neighbors=20, use_rep='X')\n",
        "sc.tl.leiden(adata, resolution=0.05)\n",
        "\n",
        "# Save Leiden labels\n",
        "\n",
        "leiden_labels = adata.obs['leiden']\n",
        "leiden_labels.to_csv('leiden_labels_all.csv', index=True, header=True)\n",
        "\n",
        "# Use original UMAP coordinates for plotting\n",
        "plt.figure(figsize=(24, 18))\n",
        "scatter = plt.scatter(umap_result[:, 0], umap_result[:, 1], c=adata.obs['leiden'].astype('category').cat.codes, cmap='tab20', s=0.5, alpha=0.2)\n",
        "plt.colorbar(scatter, ticks=range(len(adata.obs['leiden'].unique())))\n",
        "plt.title(\"UMAP with Leiden clusters\")\n",
        "plt.xlabel(\"UMAP 1\")\n",
        "plt.ylabel(\"UMAP 2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yyb0tBJBazre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate top 10 differential words between clusters based on TF-IDF score"
      ],
      "metadata": {
        "id": "JFRIor-9cN9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
        "tfidf_df['cluster'] = adata.obs['leiden'].astype(int).values\n",
        "\n",
        "# Compute mean TF-IDF scores for each word within each cluster\n",
        "cluster_means = tfidf_df.groupby('cluster').mean()\n",
        "differential_scores = {}\n",
        "for cluster in cluster_means.index:\n",
        "    other_clusters = cluster_means.drop(index=cluster)\n",
        "    differential_scores[cluster] = cluster_means.loc[cluster] - other_clusters.max()\n",
        "\n",
        "# Get the top N differential words for each cluster\n",
        "N = 10\n",
        "top_differential_words = {}\n",
        "\n",
        "for cluster in differential_scores:\n",
        "    sorted_terms = differential_scores[cluster].sort_values(ascending=False)\n",
        "    top_differential_words[cluster] = sorted_terms.head(N).index.tolist()\n",
        "\n",
        "# Convert each word to a string enclosed in single quotes for each cluster\n",
        "top_differential_words_quoted = {\n",
        "    cluster: [f\"'{word}'\" for word in words] for cluster, words in top_differential_words.items()\n",
        "}\n",
        "top_differential_words_df = pd.DataFrame(top_differential_words_quoted).transpose()\n",
        "top_differential_words_df.columns = [f\"Top {i+1}\" for i in range(len(top_differential_words_df.columns))]\n",
        "top_differential_words_df.to_csv('top_differential_words.csv', index=True)"
      ],
      "metadata": {
        "id": "iNv-DiCxbVkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the presence of top 3 differential words (stems) of each cluster in every cluster"
      ],
      "metadata": {
        "id": "0nNCqWxwe2Tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the word groups for each cluster\n",
        "word_groups = {\n",
        "    0: ['care', 'servic', 'home'],\n",
        "    1: ['rat', 'old', 'anim'],\n",
        "    2: ['cell', 'stem', 'cultur'],\n",
        "    3: ['elderli', 'outcom', 'sever'],\n",
        "    4: ['protein', 'beta', 'receptor'],\n",
        "    5: ['model', 'method', 'estim'],\n",
        "    6: ['social', 'research', 'older'],\n",
        "    7: ['stress', 'oxid', 'metabol'],\n",
        "    8: ['acid', 'surfac', 'water'],\n",
        "    9: ['cognit', 'dementia', 'declin'],\n",
        "    10: ['diabet', 'food', 'obes'],\n",
        "    11: ['gene', 'express', 'mutat'],\n",
        "    12: ['mice', 'mous', 'strain'],\n",
        "    13: ['subject', 'children', 'region'],\n",
        "    14: ['risk', 'factor', 'stroke'],\n",
        "    15: ['memori', 'task', 'perform'],\n",
        "    16: ['femal', 'male', 'dai'],\n",
        "    17: ['muscl', 'skelet', 'strength'],\n",
        "    18: ['mitochondri', 'dna', 'damag'],\n",
        "    19: ['cycl', 'induc', 'growth'],\n",
        "    20: ['men', 'hormon', 'lower'],\n",
        "    21: ['skin', 'exposur', 'product'],\n",
        "    22: ['densiti', 'vitamin', 'bone'],\n",
        "    23: ['neuron', 'cortex', 'motor'],\n",
        "    25: ['train', 'improv', 'exercis'],\n",
        "    26: ['cancer', 'lung', 'surviv'],\n",
        "    27: ['arteri', 'blood', 'pressur'],\n",
        "    28: ['symptom', 'scale', 'examin'],\n",
        "    29: ['telomer', 'length', 'end'],\n",
        "    30: ['sleep', 'disord', 'behavior']\n",
        "}\n",
        "\n",
        "# Define cluster names\n",
        "cluster_names = {\n",
        "    0: 'Healthcare', 1: 'Animal studies', 2: 'Stem cells', 3: 'Geriatrics', 4: 'Molecular biology', 5: 'Statistics',\n",
        "    6: 'Social', 7: 'Oxidative stress', 8: 'Physics', 9: 'Dementia', 10: 'Diabetes and nutrition', 11: 'Genetics',\n",
        "    12: 'Mouse studies', 13: 'Brain structure', 14: 'Risk factors', 15: 'Cognition', 16: 'Gender', 17: 'Muscle',\n",
        "    18: 'Mitochondria and DNA damage', 19: 'Cell cycle and senescence', 20: 'Hormonal changes', 21: 'Skin', 22: 'Bone',\n",
        "    23: 'Neural tissue', 25: 'Exercise', 26: 'Cancer', 27: 'Vascular', 28: 'Clinical evaluation', 29: 'Telomeres', 30: 'Sleep'\n",
        "}\n",
        "\n",
        "# Function to check for presence of each word\n",
        "unique_words = list(set(word for words_list in word_groups.values() for word in words_list))\n",
        "word_presence_matrix = pd.DataFrame(0, index=cluster_names.values(), columns=word_groups.keys())\n",
        "def check_word_group_presence(doc, word_group):\n",
        "    return any(re.search(r'\\b' + word + r'\\b', doc) for word in word_group)\n",
        "\n",
        "# Combine the necessary data by using the 'leiden' column from leiden_labels\n",
        "preprocessed_docs_df = pd.DataFrame(preprocessed_docs, columns=['Abstract'])\n",
        "if len(preprocessed_docs_df) != len(leiden_labels):\n",
        "    raise ValueError(\"The lengths of preprocessed_docs and leiden_labels do not match!\")\n",
        "preprocessed_docs_df['leiden'] = leiden_labels['leiden'].values\n",
        "\n",
        "# Ensure all entries in the 'Abstract' column are strings\n",
        "preprocessed_docs_df['Abstract'] = preprocessed_docs_df['Abstract'].astype(str)\n",
        "\n",
        "# Process the documents to check for word group presence\n",
        "for cluster, cluster_name in cluster_names.items():\n",
        "    cluster_docs = preprocessed_docs_df[preprocessed_docs_df['leiden'] == cluster]['Abstract']\n",
        "    total_docs_in_cluster = len(cluster_docs)\n",
        "    for group, words in word_groups.items():\n",
        "        word_group_presence_count = sum(check_word_group_presence(doc, words) for doc in cluster_docs)\n",
        "        word_presence_matrix.at[cluster_name, group] = word_group_presence_count / total_docs_in_cluster if total_docs_in_cluster > 0 else 0"
      ],
      "metadata": {
        "id": "PnY9dCI2fMpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the heatmap\n",
        "x_labels = [', '.join([word.capitalize() for word in group]) for group in word_groups.values()]\n",
        "word_presence_matrix = word_presence_matrix.sort_index(axis=1)\n",
        "\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.heatmap(word_presence_matrix, cmap='RdBu_r', cbar=True, annot=False)\n",
        "plt.ylabel('Clusters', fontsize=20)\n",
        "plt.xlabel('Top Differential Words', fontsize=20)\n",
        "plt.title('Top Differential Words Presence in Clusters', fontsize=20)\n",
        "plt.xticks(ticks=np.arange(len(x_labels))+0.5, labels=x_labels, rotation=90, fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "plt.savefig('Heatmap of Word Group Presence in Clusters.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "abMCSdC1e0ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate and plot number of documents per cluster"
      ],
      "metadata": {
        "id": "ZLn8gLPBdEf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert UMAP results to a DataFrame\n",
        "umap_df = pd.DataFrame(umap_result, columns=['UMAP1', 'UMAP2'])\n",
        "\n",
        "# Add leiden labels to the combined dataframe\n",
        "combined_df = pd.concat([umap_df, leiden_labels], axis=1)\n",
        "\n",
        "# Replace cluster numbers with names\n",
        "combined_df['Cluster Name'] = combined_df['leiden'].map(cluster_names)\n",
        "\n",
        "# Count the number of documents per cluster\n",
        "cluster_counts = combined_df['Cluster Name'].value_counts().reset_index()\n",
        "cluster_counts.columns = ['Cluster Name', 'Count']\n",
        "cluster_counts = cluster_counts.sort_values(by='Count', ascending=False)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(24, 16))\n",
        "sns.barplot(data=cluster_counts, x='Cluster Name', y='Count', palette='RdBu')\n",
        "plt.xticks(rotation=90, fontsize=18)\n",
        "plt.yticks(fontsize=18, fontfamily='serif')\n",
        "plt.title('Number of Documents per Cluster', fontsize=28)\n",
        "plt.ylabel('Number of Documents', fontsize=24)\n",
        "plt.xlabel('')\n",
        "plt.savefig('Number of Documents per Cluster.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4PMpbxbcTmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cosine similarity"
      ],
      "metadata": {
        "id": "0441bUewelcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign TF-IDF vectors to clusters based on leiden labels\n",
        "leiden_labels['tfidf'] = list(tfidf_matrix.toarray())\n",
        "\n",
        "# Group by clusters and compute the mean TF-IDF vector for each cluster\n",
        "cluster_tfidf = leiden_labels.groupby('leiden')['tfidf'].apply(lambda x: np.mean(np.stack(x.values), axis=0))\n",
        "\n",
        "# Compute cosine similarity matrix between cluster mean TF-IDF vectors\n",
        "cos_sim_matrix = cosine_similarity(np.stack(cluster_tfidf.values))\n",
        "valid_clusters = [label for label in cluster_tfidf.index if label in cluster_names]\n",
        "cluster_tfidf = cluster_tfidf[valid_clusters]\n",
        "\n",
        "# Create the cosine similarity DataFrame with correct labels\n",
        "cos_sim_df = pd.DataFrame(cos_sim_matrix, index=[cluster_names[label] for label in valid_clusters], columns=[cluster_names[label] for label in valid_clusters])\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.heatmap(cos_sim_df, annot=False, cmap='RdBu_r')\n",
        "plt.title('Cosine Similarity Between Clusters Based on TF-IDF', fontsize=20)\n",
        "plt.ylabel('Clusters', fontsize=20)\n",
        "plt.xlabel('Clusters', fontsize=20)\n",
        "plt.xticks(rotation=90, fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "plt.savefig('Cosine Similarity TFIDF Heatmap.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xQ05uHx8eq-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot presence of keywords in UMAP"
      ],
      "metadata": {
        "id": "tlQaZvS1g975"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = ['clinic', 'health', 'care', 'patient', 'treatment']\n",
        "keyword_counts = np.array([sum(kw in doc for kw in keywords) for doc in preprocessed_docs])\n",
        "\n",
        "# Normalize the Counts\n",
        "max_count = np.max(keyword_counts)\n",
        "normalized_counts = keyword_counts / max_count if max_count > 0 else np.zeros_like(keyword_counts)\n",
        "\n",
        "# Plot\n",
        "cmap = plt.get_cmap('viridis')\n",
        "colors = cmap(normalized_counts)\n",
        "plt.figure(figsize=(18, 12))\n",
        "scatter = plt.scatter(umap_result3[:, 0], umap_result3[:, 1], color=colors, s=0.5, alpha=0.2)\n",
        "plt.title(\"UMAP Visualization with Keyword Presence Gradient\")\n",
        "plt.xlabel(\"UMAP 1\")\n",
        "plt.ylabel(\"UMAP 2\")\n",
        "cbar = plt.colorbar(mappable=plt.cm.ScalarMappable(cmap=cmap), ax=plt.gca())\n",
        "cbar.set_label('Keyword Presence')\n",
        "plt.savefig('UMAP keywords.png', dpi=600)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HCLu_Rh1hreD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Topic enrichment calculation in leiden clusters and hierarchical clustering"
      ],
      "metadata": {
        "id": "98Tw9HMWjdLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get topic distribution for each document\n",
        "def get_topic_distribution(lda_model, corpus):\n",
        "    topic_distributions = []\n",
        "    for doc in corpus:\n",
        "        topic_distribution = lda_model.get_document_topics(doc, minimum_probability=0)\n",
        "        topic_distributions.append([prob for _, prob in topic_distribution])\n",
        "    return np.array(topic_distributions)\n",
        "\n",
        "topic_distributions = get_topic_distribution(lda_model, bow_corpus)\n",
        "\n",
        "# Add leiden labels to the dataframe\n",
        "df['leiden'] = leiden_labels['leiden'].values\n",
        "\n",
        "# Calculate enrichment score\n",
        "def calculate_enrichment_scores(topic_distributions, clusters, num_topics):\n",
        "    enrichment_scores = []\n",
        "    for cluster_id in np.unique(clusters):\n",
        "        cluster_indices = np.where(clusters == cluster_id)[0]\n",
        "        non_cluster_indices = np.where(clusters != cluster_id)[0]\n",
        "\n",
        "        cluster_topic_sums = topic_distributions[cluster_indices].sum(axis=0)\n",
        "        non_cluster_topic_sums = topic_distributions[non_cluster_indices].sum(axis=0)\n",
        "\n",
        "        for topic_id in range(num_topics):\n",
        "            cluster_sum = cluster_topic_sums[topic_id]\n",
        "            non_cluster_sum = non_cluster_topic_sums[topic_id]\n",
        "\n",
        "            expected_cluster_sum = len(cluster_indices) * (cluster_sum + non_cluster_sum) / len(clusters)\n",
        "\n",
        "            # Avoid division by zero or log of zero\n",
        "            if expected_cluster_sum > 0 and cluster_sum > 0:\n",
        "                enrichment_score = np.log2(cluster_sum / expected_cluster_sum)\n",
        "                enrichment_scores.append((cluster_id, topic_id, enrichment_score))\n",
        "\n",
        "    return enrichment_scores\n",
        "\n",
        "enrichment_scores = calculate_enrichment_scores(topic_distributions, df['leiden'].values, num_topics)\n",
        "\n",
        "# Convert results to DataFrame\n",
        "enrichment_score_df = pd.DataFrame(enrichment_scores, columns=['Cluster', 'Topic', 'Enrichment Score'])\n",
        "enrichment_score_df['Cluster Name'] = enrichment_score_df['Cluster'].map(cluster_names)\n",
        "enrichment_score_df['Topic Name'] = enrichment_score_df['Topic'].map(dict(enumerate(topic_names)))"
      ],
      "metadata": {
        "id": "kRAX1K-IlhxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_mapping = {\n",
        "    0: \"Cell signaling\", 1: \"Development\", 2: \"CNS diseases\", 3: \"Cardiovascular\",\n",
        "    4: \"Age-related decline\", 5: \"Risk factors\", 6: \"Cell biology\", 7: \"Gender\",\n",
        "    8: \"Muscle\", 9: \"Oxidative stress\", 10: \"Bone\", 11: \"Therapeutics\", 12: \"Metabolism\",\n",
        "    13: \"Neural tissue\", 14: \"Clinics\", 15: \"Healthcare\", 16: \"General terms\",\n",
        "    17: \"Brain structure\", 18: \"Psychosocial\", 19: \"Rodent studies\", 20: \"Cancer\",\n",
        "    21: \"Physical activity\", 22: \"Demography\", 23: \"Liver and kidney\", 24: \"Genetics\",\n",
        "    25: \"Analytics\", 26: \"Cognition\", 27: \"Physics\", 28: \"Skin\", 29: \"Clinical tests\"\n",
        "}\n",
        "\n",
        "# Define the order of topics\n",
        "topic_order = [\n",
        "    \"General terms\", \"Healthcare\", \"Cell biology\", \"Genetics\", \"Analytics\",\n",
        "    \"Cell signaling\", \"Demography\", \"Clinical tests\", \"Age-related decline\",\n",
        "    \"Rodent studies\", \"Clinics\", \"Psychosocial\", \"Oxidative stress\", \"Physics\",\n",
        "    \"Therapeutics\", \"Risk factors\", \"Development\", \"Cognition\", \"CNS diseases\", \"Skin\",\n",
        "    \"Neural tissue\", \"Brain structure\", \"Cancer\", \"Metabolism\", \"Physical activity\",\n",
        "    \"Cardiovascular\", \"Gender\", \"Muscle\", \"Bone\", \"Liver and kidney\"\n",
        "]\n",
        "\n",
        "enrichment_score_df['Topic Name'] = enrichment_score_df['Topic'].map(topic_mapping)\n",
        "cluster_order = list(cluster_names.values())\n",
        "heatmap_data = enrichment_score_df.pivot(index='Cluster Name', columns='Topic Name', values='Enrichment Score')\n",
        "heatmap_data = heatmap_data.reindex(index=cluster_order, columns=topic_order)\n",
        "\n",
        "# Create a clustermap\n",
        "g = sns.clustermap(\n",
        "    heatmap_data,\n",
        "    cmap=\"RdBu_r\",\n",
        "    figsize=(20, 18),\n",
        "    cbar_kws={'label': 'Enrichment Score'},\n",
        "    annot=False,\n",
        "    fmt=\".2f\",\n",
        "    dendrogram_ratio=(.05, .05),  # adjust these to change dendrogram size\n",
        "    metric='euclidean',  # distance metric\n",
        "    method='average',  # linkage method\n",
        "    standard_scale=1  # normalize data\n",
        ")\n",
        "\n",
        "plt.gcf().suptitle('Heatmap of Topic Enrichment', fontsize=22, y=1.05)\n",
        "g.ax_heatmap.set_xlabel('Topic', fontsize=20)\n",
        "g.ax_heatmap.set_ylabel('Cluster', fontsize=20)\n",
        "plt.setp(g.ax_heatmap.get_xticklabels(), rotation=45, ha='right', fontsize=16)\n",
        "plt.setp(g.ax_heatmap.get_yticklabels(), rotation=0, fontsize=16)\n",
        "cbar = g.ax_heatmap.collections[0].colorbar\n",
        "cbar.ax.tick_params(labelsize=12)\n",
        "cbar.set_label('Enrichment Score (Normalized)', fontsize=12)\n",
        "cbar.ax.set_position([0.95, 0.05, 0.03, 0.1])\n",
        "plt.savefig('Clustermap Enrichment Score.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AUI8PnbJj0A8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}