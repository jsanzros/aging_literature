{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYi5YfduZcgN"
      },
      "outputs": [],
      "source": [
        "! pip install pandas==2.2.2 numpy==1.24.4 umap==0.1.1 umap-learn==0.5.7 scipy==1.13.1 scikit-learn==1.5.2 matplotlib==3.10.0 seaborn==0.13.2 scanpy==1.11.1 anndata==0.11.4 igraph==0.11.8 leidenalg==0.10.2 gensim==4.3.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh_AdxVEZdHi"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "import umap\n",
        "import matplotlib.pyplot as plt\n",
        "import scanpy as sc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from anndata import AnnData\n",
        "import leidenalg\n",
        "import seaborn as sns\n",
        "import re\n",
        "from scipy.stats import fisher_exact\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNlFYxX5aZ2i"
      },
      "source": [
        "Load preprocessed files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPqA0LO8ZdJV"
      },
      "outputs": [],
      "source": [
        "with open('lda_model.pkl', 'rb') as f:\n",
        "    lda_model = pickle.load(f)\n",
        "\n",
        "with open('preprocessed_docs.pkl', 'rb') as f:\n",
        "    preprocessed_docs = pickle.load(f)\n",
        "\n",
        "with open('bow_corpus.pkl', 'rb') as f:\n",
        "    bow_corpus = pickle.load(f)\n",
        "\n",
        "with open('dictionary.dict', 'rb') as f:\n",
        "    dictionary = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kId5q7HdZCof"
      },
      "source": [
        "TF-IDF vectorization, PCA and UMAP of all documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGyA9i6VXjG2"
      },
      "outputs": [],
      "source": [
        "# Convert preprocessed documents back to text\n",
        "preprocessed_texts = preprocessed_docs.apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Create TF-IDF matrix\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=500)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_texts)\n",
        "\n",
        "# Perform PCA on TF-IDF matrix\n",
        "pca = PCA(n_components=50)\n",
        "pca_result = pca.fit_transform(tfidf_matrix.toarray())\n",
        "\n",
        "# Perform UMAP on PCA result\n",
        "umap_model = umap.UMAP(n_neighbors=5, min_dist=0, n_components=2)\n",
        "umap_result = umap_model.fit_transform(pca_result)\n",
        "\n",
        "# Plot UMAP\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(umap_result[:, 0], umap_result[:, 1], cmap='viridis', s=1, alpha=0.2)\n",
        "plt.title('UMAP Visualization of Documents')\n",
        "plt.xlabel('UMAP 1')\n",
        "plt.ylabel('UMAP 2')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# Save UMAP embeddings\n",
        "with open(\"umap_result.pkl\", \"wb\") as f:\n",
        "    pickle.dump(umap_result, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_7QFf1_a-56"
      },
      "source": [
        "Leiden clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yyb0tBJBazre"
      },
      "outputs": [],
      "source": [
        "# Convert your PCA result into an AnnData object\n",
        "adata = AnnData(X=pca_result)\n",
        "\n",
        "# Compute the k-nearest neighbors graph and run Leiden clustering\n",
        "sc.pp.neighbors(adata, n_neighbors=5, use_rep='X')\n",
        "sc.tl.leiden(adata, resolution=0.7, flavor='igraph', directed=False, n_iterations=2)\n",
        "\n",
        "# Save Leiden labels\n",
        "\n",
        "leiden_labels = adata.obs['leiden']\n",
        "leiden_labels.to_csv('leiden_labels_all.csv', index=True, header=True)\n",
        "\n",
        "# Use original UMAP coordinates for plotting\n",
        "plt.figure(figsize=(24, 18))\n",
        "scatter = plt.scatter(umap_result[:, 0], umap_result[:, 1], c=adata.obs['leiden'].astype('category').cat.codes, cmap='tab20', s=0.5, alpha=0.2)\n",
        "plt.colorbar(scatter, ticks=range(len(adata.obs['leiden'].unique())))\n",
        "plt.title(\"UMAP with Leiden clusters\")\n",
        "plt.xlabel(\"UMAP 1\")\n",
        "plt.ylabel(\"UMAP 2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFRIor-9cN9u"
      },
      "source": [
        "Calculate top 10 differential words between clusters based on TF-IDF score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNv-DiCxbVkU"
      },
      "outputs": [],
      "source": [
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
        "tfidf_df['cluster'] = adata.obs['leiden'].astype(int).values\n",
        "\n",
        "# Compute mean TF-IDF scores for each word within each cluster\n",
        "cluster_means = tfidf_df.groupby('cluster').mean()\n",
        "differential_scores = {}\n",
        "for cluster in cluster_means.index:\n",
        "    other_clusters = cluster_means.drop(index=cluster)\n",
        "    differential_scores[cluster] = cluster_means.loc[cluster] - other_clusters.max()\n",
        "\n",
        "# Get the top N differential words for each cluster\n",
        "N = 10\n",
        "top_differential_words = {}\n",
        "\n",
        "for cluster in differential_scores:\n",
        "    sorted_terms = differential_scores[cluster].sort_values(ascending=False)\n",
        "    top_differential_words[cluster] = sorted_terms.head(N).index.tolist()\n",
        "\n",
        "# Convert each word to a string enclosed in single quotes for each cluster\n",
        "top_differential_words_quoted = {\n",
        "    cluster: [f\"'{word}'\" for word in words] for cluster, words in top_differential_words.items()\n",
        "}\n",
        "top_differential_words_df = pd.DataFrame(top_differential_words_quoted).transpose()\n",
        "top_differential_words_df.columns = [f\"Top {i+1}\" for i in range(len(top_differential_words_df.columns))]\n",
        "top_differential_words_df.to_csv('top_differential_words.csv', index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nNCqWxwe2Tk"
      },
      "source": [
        "Calculate the presence of top 3 differential words (stems) of each cluster in every cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnY9dCI2fMpI"
      },
      "outputs": [],
      "source": [
        "# Define the word groups for each cluster\n",
        "word_groups = {\n",
        "    0: ['cognit', 'dementia', 'impair'],\n",
        "    1: ['mutat', 'genet', 'gene'],\n",
        "    2: ['patient', 'drug', 'elderli'],\n",
        "    3: ['femal', 'male', 'sex'],\n",
        "    4: ['express', 'mrna', 'stem'],\n",
        "    5: ['exercis', 'train', 'physic'],\n",
        "    6: ['diabet', 'insulin', 'glucos'],\n",
        "    7: ['women', 'men', 'serum'],\n",
        "    8: ['diet', 'acid', 'intak'],\n",
        "    9: ['model', 'estim', 'data'],\n",
        "    10: ['diseas', 'review', 'relat'],\n",
        "    11: ['depress', 'symptom', 'scale'],\n",
        "    12: ['immun', 'infect', 'respons'],\n",
        "    13: ['brain', 'region', 'network'],\n",
        "    14: ['adult', 'memori', 'task'],\n",
        "    15: ['care', 'health', 'servic'],\n",
        "    16: ['oxid', 'stress', 'antioxid'],\n",
        "    17: ['rat', 'dai', 'anim'],\n",
        "    18: ['muscl', 'skelet', 'mass'],\n",
        "    19: ['dna', 'repair', 'damag'],\n",
        "    20: ['group', 'year', 'significantli'],\n",
        "    21: ['neuron', 'protein', 'beta'],\n",
        "    22: ['pressur', 'arteri', 'blood'],\n",
        "    23: ['skin', 'exposur', 'appear'],\n",
        "    24: ['telomer', 'length', 'end'],\n",
        "    25: ['cancer', 'tumor', 'lung'],\n",
        "    26: ['senesc', 'cellular', 'induc'],\n",
        "    27: ['mitochondri', 'dysfunct', 'complex'],\n",
        "    28: ['sleep', 'qualiti', 'behavior'],\n",
        "    29: ['mice', 'mous', 'defici'],\n",
        "    30: ['bone', 'densiti', 'loss'],\n",
        "    31: ['temperatur', 'surfac', 'water']\n",
        "}\n",
        "\n",
        "cluster_names = {\n",
        "    0: 'Dementia', 1: 'Genetics', 2: 'Geriatrics', 3: 'Gender', 4: 'Cell signaling & stem cells',\n",
        "    5: 'Exercise', 6: 'Diabetes', 7: 'Hormones', 8: 'Nutrition', 9: 'Statistics',\n",
        "    10: 'Broad aging terminology', 11: 'Depression & psychology', 12: 'Immunology',\n",
        "    13: 'Brain structure', 14: 'Memory & learning', 15: 'Healthcare', 16: 'Oxidative stress',\n",
        "    17: 'Animal studies', 18: 'Muscle', 19: 'DNA damage', 20: 'Comparative studies',\n",
        "    21: \"Alzheimer's\", 22: 'Vascular', 23: 'Skin', 24: 'Telomeres', 25: 'Cancer',\n",
        "    26: 'Cell cycle & senescence', 27: 'Mitochondria', 28: 'Sleep', 29: 'Mouse studies',\n",
        "    30: 'Bone', 31: 'Physics'\n",
        "}\n",
        "\n",
        "# Function to check for presence of each word\n",
        "unique_words = list(set(word for words_list in word_groups.values() for word in words_list))\n",
        "word_presence_matrix = pd.DataFrame(0, index=cluster_names.values(), columns=word_groups.keys())\n",
        "def check_word_group_presence(doc, word_group):\n",
        "    return any(re.search(r'\\b' + word + r'\\b', doc) for word in word_group)\n",
        "\n",
        "# Combine the necessary data by using the 'leiden' column from leiden_labels\n",
        "preprocessed_docs_df = pd.DataFrame(preprocessed_docs, columns=['Abstract'])\n",
        "if len(preprocessed_docs_df) != len(leiden_labels):\n",
        "    raise ValueError(\"The lengths of preprocessed_docs and leiden_labels do not match!\")\n",
        "preprocessed_docs_df['leiden'] = leiden_labels['leiden'].values\n",
        "\n",
        "# Ensure all entries in the 'Abstract' column are strings\n",
        "preprocessed_docs_df['Abstract'] = preprocessed_docs_df['Abstract'].astype(str)\n",
        "\n",
        "# Process the documents to check for word group presence\n",
        "for cluster, cluster_name in cluster_names.items():\n",
        "    cluster_docs = preprocessed_docs_df[preprocessed_docs_df['leiden'] == cluster]['Abstract']\n",
        "    total_docs_in_cluster = len(cluster_docs)\n",
        "    for group, words in word_groups.items():\n",
        "        word_group_presence_count = sum(check_word_group_presence(doc, words) for doc in cluster_docs)\n",
        "        word_presence_matrix.at[cluster_name, group] = word_group_presence_count / total_docs_in_cluster if total_docs_in_cluster > 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abMCSdC1e0ep"
      },
      "outputs": [],
      "source": [
        "# Calculate document counts per cluster\n",
        "cluster_doc_counts = preprocessed_docs_df['leiden'].value_counts()\n",
        "sorted_cluster_ids = cluster_doc_counts.sort_values(ascending=False).index.tolist()\n",
        "\n",
        "# Sort the word_presence_matrix rows by cluster name using sorted cluster IDs\n",
        "sorted_cluster_names = [cluster_names[i] for i in sorted_cluster_ids]\n",
        "word_presence_matrix_sorted = word_presence_matrix.loc[sorted_cluster_names]\n",
        "\n",
        "# Reorder the columns to match the sorted clusters\n",
        "sorted_columns = sorted_cluster_ids\n",
        "word_presence_matrix_sorted = word_presence_matrix_sorted[sorted_columns]\n",
        "x_labels = [', '.join([word.capitalize() for word in word_groups[i]]) for i in sorted_columns]\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.heatmap(word_presence_matrix_sorted, cmap='RdBu_r', cbar=True, annot=False)\n",
        "plt.ylabel('Clusters', fontsize=20)\n",
        "plt.xlabel('Top Differential Words', fontsize=24)\n",
        "plt.title('Top Differential Words Presence in Clusters', fontsize=24)\n",
        "plt.xticks(ticks=np.arange(len(x_labels)) + 0.5, labels=x_labels, rotation=90, fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.savefig('Heatmap_of_Word_Group_Presence_in_Clusters.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLn8gLPBdEf9"
      },
      "source": [
        "Calculate and plot number of documents per cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4PMpbxbcTmR"
      },
      "outputs": [],
      "source": [
        "# Convert UMAP results to a DataFrame\n",
        "umap_df = pd.DataFrame(umap_result, columns=['UMAP1', 'UMAP2'])\n",
        "\n",
        "# Add leiden labels to the combined dataframe\n",
        "combined_df = pd.concat([umap_df, leiden_labels], axis=1)\n",
        "\n",
        "# Replace cluster numbers with names\n",
        "combined_df['Cluster Name'] = combined_df['leiden'].map(cluster_names)\n",
        "\n",
        "# Count the number of documents per cluster\n",
        "cluster_counts = combined_df['Cluster Name'].value_counts().reset_index()\n",
        "cluster_counts.columns = ['Cluster Name', 'Count']\n",
        "cluster_counts = cluster_counts.sort_values(by='Count', ascending=False)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(24, 16))\n",
        "sns.barplot(data=cluster_counts, x='Cluster Name', y='Count', palette='RdBu')\n",
        "plt.xticks(rotation=90, fontsize=18)\n",
        "plt.yticks(fontsize=18, fontfamily='serif')\n",
        "plt.title('Number of Documents per Cluster', fontsize=28)\n",
        "plt.ylabel('Number of Documents', fontsize=24)\n",
        "plt.xlabel('')\n",
        "plt.savefig('Number of Documents per Cluster.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0441bUewelcq"
      },
      "source": [
        "Cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQ05uHx8eq-k"
      },
      "outputs": [],
      "source": [
        "# Get cluster document counts and sort cluster IDs descending\n",
        "cluster_doc_counts = preprocessed_docs_df['leiden'].value_counts()\n",
        "sorted_cluster_ids = cluster_doc_counts.sort_values(ascending=False).index.tolist()\n",
        "\n",
        "# Filter to valid cluster IDs that exist in cluster_tfidf\n",
        "sorted_cluster_ids = [cid for cid in sorted_cluster_ids if cid in cluster_tfidf.index]\n",
        "\n",
        "# Reorder the cluster_tfidf and calculate cosine similarity\n",
        "cluster_tfidf_sorted = cluster_tfidf.loc[sorted_cluster_ids]\n",
        "cos_sim_matrix_sorted = cosine_similarity(np.stack(cluster_tfidf_sorted.values))\n",
        "sorted_cluster_names = [cluster_names[cid] for cid in sorted_cluster_ids]\n",
        "cos_sim_df_sorted = pd.DataFrame(\n",
        "    cos_sim_matrix_sorted,\n",
        "    index=sorted_cluster_names,\n",
        "    columns=sorted_cluster_names\n",
        ")\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.heatmap(cos_sim_df_sorted, annot=False, cmap='RdBu_r')\n",
        "plt.title('Cosine Similarity Between Clusters Based on TF-IDF', fontsize=24)\n",
        "plt.ylabel('Clusters', fontsize=20)\n",
        "plt.xlabel('Clusters', fontsize=20)\n",
        "plt.xticks(rotation=90, fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.savefig('Cosine_Similarity_TFIDF_Heatmap.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlQaZvS1g975"
      },
      "source": [
        "Plot presence of keywords in UMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCLu_Rh1hreD"
      },
      "outputs": [],
      "source": [
        "keywords = ['clinic', 'health', 'care', 'patient', 'treatment']\n",
        "keyword_counts = np.array([sum(kw in doc for kw in keywords) for doc in preprocessed_docs])\n",
        "\n",
        "# Normalize the Counts\n",
        "max_count = np.max(keyword_counts)\n",
        "normalized_counts = keyword_counts / max_count if max_count > 0 else np.zeros_like(keyword_counts)\n",
        "\n",
        "# Plot\n",
        "cmap = plt.get_cmap('viridis')\n",
        "colors = cmap(normalized_counts)\n",
        "plt.figure(figsize=(18, 12))\n",
        "scatter = plt.scatter(umap_result3[:, 0], umap_result3[:, 1], color=colors, s=0.5, alpha=0.2)\n",
        "plt.title(\"UMAP Visualization with Keyword Presence Gradient\")\n",
        "plt.xlabel(\"UMAP 1\")\n",
        "plt.ylabel(\"UMAP 2\")\n",
        "cbar = plt.colorbar(mappable=plt.cm.ScalarMappable(cmap=cmap), ax=plt.gca())\n",
        "cbar.set_label('Keyword Presence')\n",
        "plt.savefig('UMAP keywords.png', dpi=600)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98Tw9HMWjdLR"
      },
      "source": [
        "Topic enrichment calculation in leiden clusters and hierarchical clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRAX1K-IlhxN"
      },
      "outputs": [],
      "source": [
        "num_topics = lda_model.num_topics\n",
        "topic_names = [f\"Topic {i+1}\" for i in range(num_topics)]\n",
        "\n",
        "# Function to get topic distribution for each document\n",
        "def get_topic_distribution(lda_model, corpus):\n",
        "    topic_distributions = []\n",
        "    for doc in corpus:\n",
        "        topic_distribution = lda_model.get_document_topics(doc, minimum_probability=0)\n",
        "        topic_distributions.append([prob for _, prob in topic_distribution])\n",
        "    return np.array(topic_distributions)\n",
        "\n",
        "topic_distributions = get_topic_distribution(lda_model, bow_corpus)\n",
        "\n",
        "# Add leiden labels to the dataframe\n",
        "preprocessed_docs_df['leiden'] = leiden_labels['leiden'].values\n",
        "\n",
        "# Calculate enrichment score\n",
        "def calculate_enrichment_scores(topic_distributions, clusters, num_topics):\n",
        "    enrichment_scores = []\n",
        "    for cluster_id in np.unique(clusters):\n",
        "        cluster_indices = np.where(clusters == cluster_id)[0]\n",
        "        non_cluster_indices = np.where(clusters != cluster_id)[0]\n",
        "\n",
        "        cluster_topic_sums = topic_distributions[cluster_indices].sum(axis=0)\n",
        "        non_cluster_topic_sums = topic_distributions[non_cluster_indices].sum(axis=0)\n",
        "\n",
        "        for topic_id in range(num_topics):\n",
        "            cluster_sum = cluster_topic_sums[topic_id]\n",
        "            non_cluster_sum = non_cluster_topic_sums[topic_id]\n",
        "\n",
        "            expected_cluster_sum = len(cluster_indices) * (cluster_sum + non_cluster_sum) / len(clusters)\n",
        "\n",
        "            # Avoid division by zero or log of zero\n",
        "            if expected_cluster_sum > 0 and cluster_sum > 0:\n",
        "                enrichment_score = np.log2(cluster_sum / expected_cluster_sum)\n",
        "                enrichment_scores.append((cluster_id, topic_id, enrichment_score))\n",
        "\n",
        "    return enrichment_scores\n",
        "\n",
        "enrichment_scores = calculate_enrichment_scores(topic_distributions, preprocessed_docs_df['leiden'].values, num_topics)\n",
        "\n",
        "# Convert results to DataFrame\n",
        "enrichment_score_df = pd.DataFrame(enrichment_scores, columns=['Cluster', 'Topic', 'Enrichment Score'])\n",
        "enrichment_score_df['Cluster Name'] = enrichment_score_df['Cluster'].map(cluster_names)\n",
        "enrichment_score_df['Topic Name'] = enrichment_score_df['Topic'].map(dict(enumerate(topic_names)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUI8PnbJj0A8"
      },
      "outputs": [],
      "source": [
        "topic_mapping = {\n",
        "    0: \"Cell signaling\", 1: \"Development\", 2: \"CNS diseases\", 3: \"Cardiovascular\",\n",
        "    4: \"Age-related decline\", 5: \"Risk factors\", 6: \"Cell biology\", 7: \"Gender\",\n",
        "    8: \"Muscle\", 9: \"Oxidative stress\", 10: \"Bone\", 11: \"Therapeutics\", 12: \"Metabolism\",\n",
        "    13: \"Neural tissue\", 14: \"Clinics\", 15: \"Healthcare\", 16: \"General terms\",\n",
        "    17: \"Brain structure\", 18: \"Psychosocial\", 19: \"Rodent studies\", 20: \"Cancer\",\n",
        "    21: \"Physical activity\", 22: \"Demography\", 23: \"Liver and kidney\", 24: \"Genetics\",\n",
        "    25: \"Analytics\", 26: \"Cognition\", 27: \"Physics\", 28: \"Skin\", 29: \"Clinical tests\"\n",
        "}\n",
        "\n",
        "# Define the order of topics\n",
        "topic_order = [\n",
        "    \"General terms\", \"Healthcare\", \"Cell biology\", \"Genetics\", \"Analytics\",\n",
        "    \"Cell signaling\", \"Demography\", \"Clinical tests\", \"Age-related decline\",\n",
        "    \"Rodent studies\", \"Clinics\", \"Psychosocial\", \"Oxidative stress\", \"Physics\",\n",
        "    \"Therapeutics\", \"Risk factors\", \"Development\", \"Cognition\", \"CNS diseases\", \"Skin\",\n",
        "    \"Neural tissue\", \"Brain structure\", \"Cancer\", \"Metabolism\", \"Physical activity\",\n",
        "    \"Cardiovascular\", \"Gender\", \"Muscle\", \"Bone\", \"Liver and kidney\"\n",
        "]\n",
        "\n",
        "enrichment_score_df['Topic Name'] = enrichment_score_df['Topic'].map(topic_mapping)\n",
        "cluster_order = list(cluster_names.values())\n",
        "heatmap_data = enrichment_score_df.pivot(index='Cluster Name', columns='Topic Name', values='Enrichment Score')\n",
        "heatmap_data = heatmap_data.reindex(index=cluster_order, columns=topic_order)\n",
        "\n",
        "# Create a clustermap\n",
        "g = sns.clustermap(\n",
        "    heatmap_data,\n",
        "    cmap=\"RdBu_r\",\n",
        "    figsize=(20, 18),\n",
        "    cbar_kws={'label': 'Enrichment Score'},\n",
        "    annot=False,\n",
        "    fmt=\".2f\",\n",
        "    dendrogram_ratio=(.05, .05),  # adjust these to change dendrogram size\n",
        "    metric='euclidean',  # distance metric\n",
        "    method='average',  # linkage method\n",
        "    standard_scale=1  # normalize data\n",
        ")\n",
        "\n",
        "plt.gcf().suptitle('Heatmap of Topic Enrichment', fontsize=22, y=1.05)\n",
        "g.ax_heatmap.set_xlabel('Topic', fontsize=20)\n",
        "g.ax_heatmap.set_ylabel('Cluster', fontsize=20)\n",
        "plt.setp(g.ax_heatmap.get_xticklabels(), rotation=45, ha='right', fontsize=16)\n",
        "plt.setp(g.ax_heatmap.get_yticklabels(), rotation=0, fontsize=16)\n",
        "cbar = g.ax_heatmap.collections[0].colorbar\n",
        "cbar.ax.tick_params(labelsize=12)\n",
        "cbar.set_label('Enrichment Score (Normalized)', fontsize=12)\n",
        "cbar.ax.set_position([0.95, 0.05, 0.03, 0.1])\n",
        "plt.savefig('Clustermap Enrichment Score.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
